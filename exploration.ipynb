{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "02506ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e6197bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42  # used for reproducability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "781ae766",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"data/Books_10k.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768f83d2",
   "metadata": {},
   "source": [
    "Now that i have my data loaded in, i will take a look at a few rows to understand the type of data i am looking at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f70d9495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10e78acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rating', 'title', 'text', 'images', 'asin', 'parent_asin', 'user_id',\n",
      "       'timestamp', 'helpful_vote', 'verified_purchase'],\n",
      "      dtype='object')\n",
      "   rating                                          title  \\\n",
      "0       1  Not a watercolor book! Seems like copies imo.   \n",
      "\n",
      "                                                text  \\\n",
      "0  It is definitely not a watercolor book.  The p...   \n",
      "\n",
      "                                              images        asin parent_asin  \\\n",
      "0  [{'small_image_url': 'https://m.media-amazon.c...  B09BGPFTDB  B09BGPFTDB   \n",
      "\n",
      "                        user_id               timestamp  helpful_vote  \\\n",
      "0  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ 2022-01-17 06:06:38.485             0   \n",
      "\n",
      "   verified_purchase  \n",
      "0               True  \n",
      "      rating             title  \\\n",
      "5000       4  Informative Text   \n",
      "\n",
      "                                                   text images        asin  \\\n",
      "5000  This is a good book if you want to learn all a...     []  0071441964   \n",
      "\n",
      "     parent_asin                       user_id           timestamp  \\\n",
      "5000  0071441964  AFXF3EGQTQDXMRLDWFU7UBFQZB7Q 2008-07-23 18:20:34   \n",
      "\n",
      "      helpful_vote  verified_purchase  \n",
      "5000             5               True  \n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "print(df.iloc[[0]])\n",
    "print(df.iloc[[5000]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d2908d",
   "metadata": {},
   "source": [
    "After seeing the availible columns, and seeing a few examples i decide that the obvious target here will be the rating.   \n",
    "I see in my examples that the first example with a rating of 1 seems negative, as the user is disappointed the book is not a watercolor book, while the one rated 4 is described as a good book.\n",
    "\n",
    "So i assume the rating is done by the user, and reflects their sentiment towards the product. I decide rating will be my target variable.  \n",
    "As an input i will use the text column, as that is where the main text of the review is placed.\n",
    "\n",
    "Now that i have noted my thoughts to ensure i or others can later review biases, i will start looking at the distribution of my data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59a0e135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "1    2000\n",
       "5    2000\n",
       "4    2000\n",
       "3    2000\n",
       "2    2000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d6647ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10000.000000\n",
       "mean       871.326200\n",
       "std       1145.227031\n",
       "min          2.000000\n",
       "25%        152.000000\n",
       "50%        463.500000\n",
       "75%       1150.000000\n",
       "max      15674.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"length\"] = df[\"text\"].str.len()\n",
    "df[\"length\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cd6328",
   "metadata": {},
   "source": [
    "I see that the ratings themself are all equally weighted, so there is no need to consider imbalances of ratings.\n",
    "I should however ensure various lengths of texts are being tested, so i decide to bin each rating category into the datasets overall quantiles, and sample from each bin to ensure a representative distribtution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "daec8d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 152 464 1,150 15,674]\n"
     ]
    }
   ],
   "source": [
    "df[\"length_group\"], bins = pd.qcut(\n",
    "    df[\"length\"], q=4, labels=False, retbins=True, duplicates=\"drop\"\n",
    ")\n",
    "np.set_printoptions(suppress=True, formatter={\"float_kind\": \"{:,.0f}\".format})\n",
    "print(bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3eaea6dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>images</th>\n",
       "      <th>asin</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>helpful_vote</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>length</th>\n",
       "      <th>length_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Not a watercolor book! Seems like copies imo.</td>\n",
       "      <td>It is definitely not a watercolor book.  The p...</td>\n",
       "      <td>[{'small_image_url': 'https://m.media-amazon.c...</td>\n",
       "      <td>B09BGPFTDB</td>\n",
       "      <td>B09BGPFTDB</td>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>2022-01-17 06:06:38.485</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>1427</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                          title  \\\n",
       "0       1  Not a watercolor book! Seems like copies imo.   \n",
       "\n",
       "                                                text  \\\n",
       "0  It is definitely not a watercolor book.  The p...   \n",
       "\n",
       "                                              images        asin parent_asin  \\\n",
       "0  [{'small_image_url': 'https://m.media-amazon.c...  B09BGPFTDB  B09BGPFTDB   \n",
       "\n",
       "                        user_id               timestamp  helpful_vote  \\\n",
       "0  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ 2022-01-17 06:06:38.485             0   \n",
       "\n",
       "   verified_purchase  length  length_group  \n",
       "0               True    1427             3  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0f73f8",
   "metadata": {},
   "source": [
    "Now it is simply a matter of doing the split and saving my test and my training data.\n",
    "The test data will be used to evaluate models during test, while the training will be split further into a train and validation set later, and used for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236b14c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val set length = 2001\n",
      "train set length = 7999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2899/1770249018.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(frac=0.2, random_state=random_seed))\n"
     ]
    }
   ],
   "source": [
    "test_df = df.groupby([\"rating\", \"length_group\"], group_keys=False).apply(\n",
    "    lambda x: x.sample(frac=0.2, random_state=random_seed)\n",
    ")\n",
    "\n",
    "train_df = df.drop(val_df.index)\n",
    "print(f\"val set length = {len(val_df)}\")\n",
    "print(f\"train set length = {len(train_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6b55cd",
   "metadata": {},
   "source": [
    "I now have a split that takes distribution of rating and text length into consideration, and i am ready to start building a training pipeline and select a model.\n",
    "Last thing i will do in this notebook, is save my dataset split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0b8be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_json(\"data/train.jsonl\", orient=\"records\", lines=True, force_ascii=False)\n",
    "test_df.to_json(\"data/test.jsonl\", orient=\"records\", lines=True, force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa92879",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
